{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Pipeline\n",
    "**Author:** G8  \n",
    "**Task:** 1.1 - Single Object Image Processing  \n",
    "**Timeline:** - Feb 1, 2026\n",
    "\n",
    "**Purpose:**\n",
    "- Preprocess raw images to 224x224 RGB\n",
    "- Split into train/val/test (70/15/15)\n",
    "- Create class mapping for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "OpenCV version: 4.8.1\n",
      "NumPy version: 1.24.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Project root: /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System\n",
      "  Raw data: /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/Discriminative Project Milstone_1\n",
      "  Target size: (224, 224)\n",
      "  Split: 0.7/0.15/0.15\n"
     ]
    }
   ],
   "source": [
    "# Project paths - adjust if needed\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "RAW_DATA_PATH = PROJECT_ROOT.parent / \"Discriminative Project Milstone_1\"\n",
    "\n",
    "# Output paths\n",
    "RAW_ORGANIZED = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "PROCESSED_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"single_objects\"\n",
    "STATS_PATH = PROJECT_ROOT / \"data\" / \"statistics\"\n",
    "\n",
    "# Preprocessing parameters\n",
    "TARGET_SIZE = (224, 224)\n",
    "TRAIN_RATIO = 0.70\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Raw data: {RAW_DATA_PATH}\")\n",
    "print(f\"  Target size: {TARGET_SIZE}\")\n",
    "print(f\"  Split: {TRAIN_RATIO}/{VAL_RATIO}/{TEST_RATIO}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Organize Raw Data\n",
    "Copy from `Discriminative Project Milstone_1/*_OBJ*` to `data/raw/OBJ*/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ORGANIZING RAW DATA\n",
      "================================================================================\n",
      "\n",
      "Found 39 object folders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Organizing folders: 100%|██████████| 39/39 [00:02<00:00, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Organized 39 objects into: /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/data/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def extract_object_id(folder_name):\n",
    "    \"\"\"\n",
    "    Extract standardized object ID\n",
    "    Examples: 'images_OBJ001' -> 'OBJ001', 'IMAGES_OBJ786' -> 'OBJ786'\n",
    "    \"\"\"\n",
    "    parts = folder_name.upper().split('OBJ')\n",
    "    if len(parts) >= 2:\n",
    "        obj_num = ''.join(filter(str.isdigit, parts[1][:10]))\n",
    "        if obj_num:\n",
    "            return f\"OBJ{obj_num.zfill(3)}\"\n",
    "    return None\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ORGANIZING RAW DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Find all object folders\n",
    "obj_folders = [f for f in RAW_DATA_PATH.iterdir() if f.is_dir() and '_OBJ' in f.name.upper()]\n",
    "obj_folders.sort()\n",
    "\n",
    "print(f\"\\nFound {len(obj_folders)} object folders\")\n",
    "\n",
    "# Organize into standardized structure\n",
    "RAW_ORGANIZED.mkdir(parents=True, exist_ok=True)\n",
    "organized_count = 0\n",
    "\n",
    "for folder in tqdm(obj_folders, desc=\"Organizing folders\"):\n",
    "    obj_id = extract_object_id(folder.name)\n",
    "    if obj_id:\n",
    "        target_folder = RAW_ORGANIZED / obj_id\n",
    "        target_folder.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Copy image files\n",
    "        exts = ('.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP')\n",
    "        for img_file in folder.iterdir():\n",
    "            if img_file.suffix in exts:\n",
    "                shutil.copy2(img_file, target_folder / img_file.name)\n",
    "        \n",
    "        organized_count += 1\n",
    "\n",
    "print(f\"\\nOrganized {organized_count} objects into: {RAW_ORGANIZED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess Images\n",
    "Resize to 224x224 if need and prepare for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPROCESSING IMAGES\n",
      "================================================================================\n",
      "\n",
      "Processing 39 objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 39/39 [00:02<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total processed: 4108\n",
      "Failed: 0\n",
      "Avg per object: 105.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Preprocess single image:\n",
    "    1. Read as RGB\n",
    "    2. Resize to target_size only if needed\n",
    "    3. Keep as uint8 for storage (normalize during training)\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(img_path))\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    # BGR to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Only resize if the image size is not equal to target_size\n",
    "    if img_rgb.shape[:2] != target_size:  # img.shape[:2] gives (height, width)\n",
    "        img_rgb = cv2.resize(img_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    return img_rgb\n",
    "\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPROCESSING IMAGES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "object_folders = sorted([f for f in RAW_ORGANIZED.iterdir() if f.is_dir()])\n",
    "print(f\"\\nProcessing {len(object_folders)} objects...\")\n",
    "\n",
    "proc_stats = []\n",
    "temp_output = PROCESSED_PATH / \"all_preprocessed\"\n",
    "\n",
    "for obj_folder in tqdm(object_folders, desc=\"Processing\"):\n",
    "    obj_id = obj_folder.name\n",
    "    \n",
    "    # Get images\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.JPG', '.JPEG', '.PNG')\n",
    "    imgs = [f for f in obj_folder.iterdir() if f.suffix in exts]\n",
    "    \n",
    "    success, fail = 0, 0\n",
    "    output_folder = temp_output / obj_id\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_file in imgs:\n",
    "        try:\n",
    "            img_proc = preprocess_image(img_file, TARGET_SIZE)\n",
    "            if img_proc is not None:\n",
    "                out_path = output_folder / f\"{img_file.stem}.jpg\"\n",
    "                # Save as BGR\n",
    "                cv2.imwrite(str(out_path), cv2.cvtColor(img_proc, cv2.COLOR_RGB2BGR))\n",
    "                success += 1\n",
    "            else:\n",
    "                fail += 1\n",
    "        except Exception:\n",
    "            fail += 1\n",
    "    \n",
    "    proc_stats.append({'object_id': obj_id, 'successful': success, 'failed': fail})\n",
    "\n",
    "df_proc = pd.DataFrame(proc_stats)\n",
    "print(f\"\\nTotal processed: {df_proc['successful'].sum()}\")\n",
    "print(f\"Failed: {df_proc['failed'].sum()}\")\n",
    "print(f\"Avg per object: {df_proc['successful'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train/Val/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SPLITTING DATASET\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting: 100%|██████████| 39/39 [00:01<00:00, 24.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SPLIT SUMMARY:\n",
      "  Train: 2871 (69.9%)\n",
      "  Val:   611 (14.9%)\n",
      "  Test:  626 (15.2%)\n",
      "\n",
      "Saved: /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/data/statistics/split_distribution.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"SPLITTING DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "preprocessed_root = PROCESSED_PATH / \"all_preprocessed\"\n",
    "objects = sorted([f for f in preprocessed_root.iterdir() if f.is_dir()])\n",
    "\n",
    "split_stats = []\n",
    "\n",
    "for obj_folder in tqdm(objects, desc=\"Splitting\"):\n",
    "    obj_id = obj_folder.name\n",
    "    images = sorted(list(obj_folder.glob(\"*.jpg\")))\n",
    "    \n",
    "    if len(images) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Shuffle\n",
    "    np.random.shuffle(images)\n",
    "    \n",
    "    # Split indices\n",
    "    n = len(images)\n",
    "    train_end = int(n * TRAIN_RATIO)\n",
    "    val_end = train_end + int(n * VAL_RATIO)\n",
    "    \n",
    "    splits = {\n",
    "        'train': images[:train_end],\n",
    "        'val': images[train_end:val_end],\n",
    "        'test': images[val_end:]\n",
    "    }\n",
    "    \n",
    "    # Copy to split folders\n",
    "    for split_name, files in splits.items():\n",
    "        output_folder = PROCESSED_PATH / split_name / obj_id\n",
    "        output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        for img_file in files:\n",
    "            shutil.copy2(img_file, output_folder / img_file.name)\n",
    "    \n",
    "    split_stats.append({\n",
    "        'object_id': obj_id,\n",
    "        'total': n,\n",
    "        'train': len(splits['train']),\n",
    "        'val': len(splits['val']),\n",
    "        'test': len(splits['test'])\n",
    "    })\n",
    "\n",
    "df_split = pd.DataFrame(split_stats)\n",
    "print(f\"\\nSPLIT SUMMARY:\")\n",
    "print(f\"  Train: {df_split['train'].sum()} ({df_split['train'].sum()/df_split['total'].sum()*100:.1f}%)\")\n",
    "print(f\"  Val:   {df_split['val'].sum()} ({df_split['val'].sum()/df_split['total'].sum()*100:.1f}%)\")\n",
    "print(f\"  Test:  {df_split['test'].sum()} ({df_split['test'].sum()/df_split['total'].sum()*100:.1f}%)\")\n",
    "\n",
    "# Save stats\n",
    "df_split.to_csv(STATS_PATH / 'split_distribution.csv', index=False)\n",
    "print(f\"\\nSaved: {STATS_PATH / 'split_distribution.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Class Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREATING CLASS MAPPING\n",
      "================================================================================\n",
      "\n",
      "Total classes: 39\n",
      "\n",
      "First 10:\n",
      "  OBJ001 -> 0\n",
      "  OBJ002 -> 1\n",
      "  OBJ003 -> 2\n",
      "  OBJ004 -> 3\n",
      "  OBJ005 -> 4\n",
      "  OBJ006 -> 5\n",
      "  OBJ007 -> 6\n",
      "  OBJ008 -> 7\n",
      "  OBJ009 -> 8\n",
      "  OBJ010 -> 9\n",
      "\n",
      "Saved: /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/data/class_mapping.json\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CREATING CLASS MAPPING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_path = PROCESSED_PATH / \"train\"\n",
    "classes = sorted([f.name for f in train_path.iterdir() if f.is_dir()])\n",
    "\n",
    "class_to_idx = {cls: idx for idx, cls in enumerate(classes)}\n",
    "idx_to_class = {idx: cls for cls, idx in class_to_idx.items()}\n",
    "\n",
    "# Save mapping\n",
    "mapping = {\n",
    "    'class_to_idx': class_to_idx,\n",
    "    'idx_to_class': idx_to_class,\n",
    "    'num_classes': len(classes)\n",
    "}\n",
    "\n",
    "mapping_file = PROJECT_ROOT / \"data\" / \"class_mapping.json\"\n",
    "with open(mapping_file, 'w') as f:\n",
    "    json.dump(mapping, f, indent=2)\n",
    "\n",
    "print(f\"\\nTotal classes: {len(classes)}\")\n",
    "print(f\"\\nFirst 10:\")\n",
    "for cls, idx in list(class_to_idx.items())[:10]:\n",
    "    print(f\"  {cls} -> {idx}\")\n",
    "print(f\"\\nSaved: {mapping_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "TRAIN:\n",
      "  Objects: 39\n",
      "  Images: 2871\n",
      "  Sample shape: (224, 224, 3) (expected: 224, 224, 3)\n",
      "\n",
      "VAL:\n",
      "  Objects: 39\n",
      "  Images: 611\n",
      "  Sample shape: (224, 224, 3) (expected: 224, 224, 3)\n",
      "\n",
      "TEST:\n",
      "  Objects: 39\n",
      "  Images: 626\n",
      "  Sample shape: (224, 224, 3) (expected: 224, 224, 3)\n",
      "\n",
      "================================================================================\n",
      "TASK 1.1 COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_path = PROCESSED_PATH / split\n",
    "    objs = [f for f in split_path.iterdir() if f.is_dir()]\n",
    "    total_imgs = sum(len(list(f.glob(\"*.jpg\"))) for f in objs)\n",
    "    \n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  Objects: {len(objs)}\")\n",
    "    print(f\"  Images: {total_imgs}\")\n",
    "    \n",
    "    # Check sample image\n",
    "    for f in objs:\n",
    "        imgs = list(f.glob(\"*.jpg\"))\n",
    "        if imgs:\n",
    "            img = cv2.imread(str(imgs[0]))\n",
    "            print(f\"  Sample shape: {img.shape} (expected: 224, 224, 3)\")\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TASK 1.1 COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
