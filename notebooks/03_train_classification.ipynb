{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ALL 4 Classification Models (Optimized)\n",
    "**Author:** G8  \n",
    "**Task:** 2.1 - Train 4 CNN Models  \n",
    "**Strategy:** Unfreeze top layers for ALL transfer learning models  \n",
    "\n",
    "**Models:**\n",
    "1. Custom CNN (simplified architecture)\n",
    "2. ResNet50 (with unfrozen top 30 layers)\n",
    "3. EfficientNet-B0 (with unfrozen top 20 layers)\n",
    "4. MobileNetV2 (with unfrozen top 20 layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "Libraries imported!\n",
      "TensorFlow: 2.14.0\n",
      "GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50, EfficientNetB0, MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers.legacy import Adam  # For M1\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "\n",
    "print(\"Libraries imported!\")\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"GPU: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 39\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"processed\" / \"single_objects\"\n",
    "MODELS_PATH = PROJECT_ROOT / \"models\" / \"classification\"\n",
    "LOGS_PATH = PROJECT_ROOT / \"logs\" / \"classification\"\n",
    "\n",
    "MODELS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "LOGS_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(PROJECT_ROOT / \"data\" / \"class_mapping.json\", 'r') as f:\n",
    "    class_info = json.load(f)\n",
    "NUM_CLASSES = class_info['num_classes']\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20  # Start with 5 for testing\n",
    "\n",
    "print(f\"Classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2871 images belonging to 39 classes.\n",
      "Found 611 images belonging to 39 classes.\n",
      "Train: 2871, Val: 611\n"
     ]
    }
   ],
   "source": [
    "# Data generators with stronger augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=25,               # Increased for more face angle variety\n",
    "    width_shift_range=0.25,          # Horizontal shift\n",
    "    height_shift_range=0.25,         # Vertical shift\n",
    "    shear_range=0.2,                 # Light shear for pose variation\n",
    "    zoom_range=0.25,                 # Zoom in/out for distance changes\n",
    "    horizontal_flip=True,            # Flip horizontally (faces are symmetric)\n",
    "    brightness_range=[0.7, 1.35],    # Strong brightness variation for lighting\n",
    "    channel_shift_range=25.0,        # Color channel shift for robustness\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation & Test: only rescale (no augmentation)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create generators\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_PATH / 'train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_directory(\n",
    "    DATA_PATH / 'val',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train: {train_gen.samples}, Val: {val_gen.samples}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Custom CNN (Simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Custom CNN...\n",
      "Params: 1,697,191\n"
     ]
    }
   ],
   "source": [
    "def build_custom_cnn():\n",
    "    \"\"\"Simplified custom CNN with better regularization\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Block 1\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),  # Higher LR for from-scratch\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Building Custom CNN...\")\n",
    "model_cnn = build_custom_cnn()\n",
    "print(f\"Params: {model_cnn.count_params():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING CUSTOM CNN\n",
      "================================================================================\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.5615 - accuracy: 0.1550\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02455, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 111s 1s/step - loss: 3.5615 - accuracy: 0.1550 - val_loss: 4.7250 - val_accuracy: 0.0245 - lr: 5.0000e-04\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 2.7743 - accuracy: 0.2842\n",
      "Epoch 2: val_accuracy did not improve from 0.02455\n",
      "90/90 [==============================] - 103s 1s/step - loss: 2.7743 - accuracy: 0.2842 - val_loss: 4.9730 - val_accuracy: 0.0229 - lr: 5.0000e-04\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 2.4082 - accuracy: 0.3769\n",
      "Epoch 3: val_accuracy improved from 0.02455 to 0.03273, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 96s 1s/step - loss: 2.4082 - accuracy: 0.3769 - val_loss: 5.7123 - val_accuracy: 0.0327 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 2.1231 - accuracy: 0.4472\n",
      "Epoch 4: val_accuracy improved from 0.03273 to 0.05074, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "90/90 [==============================] - 92s 1s/step - loss: 2.1231 - accuracy: 0.4472 - val_loss: 5.3519 - val_accuracy: 0.0507 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.8985 - accuracy: 0.5099\n",
      "Epoch 5: val_accuracy improved from 0.05074 to 0.09165, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 88s 981ms/step - loss: 1.8985 - accuracy: 0.5099 - val_loss: 4.8508 - val_accuracy: 0.0917 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.7224 - accuracy: 0.5587\n",
      "Epoch 6: val_accuracy improved from 0.09165 to 0.15057, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 91s 1s/step - loss: 1.7224 - accuracy: 0.5587 - val_loss: 3.5015 - val_accuracy: 0.1506 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.6009 - accuracy: 0.5768\n",
      "Epoch 7: val_accuracy improved from 0.15057 to 0.19640, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 90s 996ms/step - loss: 1.6009 - accuracy: 0.5768 - val_loss: 3.2282 - val_accuracy: 0.1964 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.5125 - accuracy: 0.6036\n",
      "Epoch 8: val_accuracy improved from 0.19640 to 0.43208, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 87s 969ms/step - loss: 1.5125 - accuracy: 0.6036 - val_loss: 2.0823 - val_accuracy: 0.4321 - lr: 2.5000e-04\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.4522 - accuracy: 0.6189\n",
      "Epoch 9: val_accuracy improved from 0.43208 to 0.46481, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 84s 930ms/step - loss: 1.4522 - accuracy: 0.6189 - val_loss: 1.8364 - val_accuracy: 0.4648 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.3761 - accuracy: 0.6350\n",
      "Epoch 10: val_accuracy improved from 0.46481 to 0.51227, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 83s 924ms/step - loss: 1.3761 - accuracy: 0.6350 - val_loss: 1.7192 - val_accuracy: 0.5123 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.2534 - accuracy: 0.6479\n",
      "Epoch 11: val_accuracy improved from 0.51227 to 0.60393, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 83s 920ms/step - loss: 1.2534 - accuracy: 0.6479 - val_loss: 1.3541 - val_accuracy: 0.6039 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.2104 - accuracy: 0.6782\n",
      "Epoch 12: val_accuracy improved from 0.60393 to 0.73486, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 92s 1s/step - loss: 1.2104 - accuracy: 0.6782 - val_loss: 1.0007 - val_accuracy: 0.7349 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.1398 - accuracy: 0.6883\n",
      "Epoch 13: val_accuracy did not improve from 0.73486\n",
      "90/90 [==============================] - 91s 1s/step - loss: 1.1398 - accuracy: 0.6883 - val_loss: 1.1177 - val_accuracy: 0.6825 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.1195 - accuracy: 0.7032\n",
      "Epoch 14: val_accuracy did not improve from 0.73486\n",
      "90/90 [==============================] - 117s 1s/step - loss: 1.1195 - accuracy: 0.7032 - val_loss: 1.0647 - val_accuracy: 0.7070 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.7168\n",
      "Epoch 15: val_accuracy did not improve from 0.73486\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "90/90 [==============================] - 78s 867ms/step - loss: 1.0020 - accuracy: 0.7168 - val_loss: 1.7591 - val_accuracy: 0.5499 - lr: 2.5000e-04\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.9032 - accuracy: 0.7541\n",
      "Epoch 16: val_accuracy did not improve from 0.73486\n",
      "90/90 [==============================] - 77s 857ms/step - loss: 0.9032 - accuracy: 0.7541 - val_loss: 1.3953 - val_accuracy: 0.6268 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.8570 - accuracy: 0.7673\n",
      "Epoch 17: val_accuracy improved from 0.73486 to 0.76432, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 76s 840ms/step - loss: 0.8570 - accuracy: 0.7673 - val_loss: 0.7888 - val_accuracy: 0.7643 - lr: 1.2500e-04\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.8553 - accuracy: 0.7726\n",
      "Epoch 18: val_accuracy did not improve from 0.76432\n",
      "90/90 [==============================] - 72s 799ms/step - loss: 0.8553 - accuracy: 0.7726 - val_loss: 1.1356 - val_accuracy: 0.6939 - lr: 1.2500e-04\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.7950 - accuracy: 0.7886\n",
      "Epoch 19: val_accuracy improved from 0.76432 to 0.80687, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 71s 785ms/step - loss: 0.7950 - accuracy: 0.7886 - val_loss: 0.7128 - val_accuracy: 0.8069 - lr: 1.2500e-04\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.7637 - accuracy: 0.7941\n",
      "Epoch 20: val_accuracy improved from 0.80687 to 0.86416, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/custom_cnn_best.h5\n",
      "90/90 [==============================] - 71s 785ms/step - loss: 0.7637 - accuracy: 0.7941 - val_loss: 0.5204 - val_accuracy: 0.8642 - lr: 1.2500e-04\n",
      "\n",
      "Best: 0.8642\n"
     ]
    }
   ],
   "source": [
    "# Train Custom CNN\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING CUSTOM CNN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "callbacks_cnn = [\n",
    "    ModelCheckpoint(str(MODELS_PATH / 'custom_cnn_best.h5'), monitor='val_accuracy', \n",
    "                    save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history_cnn = model_cnn.fit(\n",
    "    train_gen, epochs=EPOCHS, validation_data=val_gen,\n",
    "    callbacks=callbacks_cnn, verbose=1\n",
    ")\n",
    "\n",
    "model_cnn.save(MODELS_PATH / 'custom_cnn_last.h5')\n",
    "print(f\"\\nBest: {max(history_cnn.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: ResNet50 (Fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building ResNet50...\n",
      "Trainable params: 15,523,367\n"
     ]
    }
   ],
   "source": [
    "def build_resnet50():\n",
    "    \"\"\"ResNet50 with top layers unfrozen for fine-tuning\"\"\"\n",
    "    base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Unfreeze top 30 layers\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0005),  # Higher for fine-tuning\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Building ResNet50...\")\n",
    "model_resnet = build_resnet50()\n",
    "trainable = sum([tf.size(w).numpy() for w in model_resnet.trainable_weights])\n",
    "print(f\"Trainable params: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING RESNET50\n",
      "================================================================================\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 4.0475 - accuracy: 0.0916\n",
      "Epoch 1: val_accuracy improved from -inf to 0.14730, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 46s 494ms/step - loss: 4.0475 - accuracy: 0.0916 - val_loss: 3.4146 - val_accuracy: 0.1473 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.9165 - accuracy: 0.0975\n",
      "Epoch 2: val_accuracy improved from 0.14730 to 0.18985, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 44s 484ms/step - loss: 3.9165 - accuracy: 0.0975 - val_loss: 3.3558 - val_accuracy: 0.1899 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.8031 - accuracy: 0.1296\n",
      "Epoch 3: val_accuracy improved from 0.18985 to 0.22095, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 48s 527ms/step - loss: 3.8031 - accuracy: 0.1296 - val_loss: 3.1987 - val_accuracy: 0.2209 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.7230 - accuracy: 0.1223\n",
      "Epoch 4: val_accuracy did not improve from 0.22095\n",
      "90/90 [==============================] - 53s 592ms/step - loss: 3.7230 - accuracy: 0.1223 - val_loss: 3.4926 - val_accuracy: 0.1702 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.6426 - accuracy: 0.1324\n",
      "Epoch 5: val_accuracy did not improve from 0.22095\n",
      "90/90 [==============================] - 57s 633ms/step - loss: 3.6426 - accuracy: 0.1324 - val_loss: 3.2877 - val_accuracy: 0.1849 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.5608 - accuracy: 0.1418\n",
      "Epoch 6: val_accuracy improved from 0.22095 to 0.24714, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 59s 650ms/step - loss: 3.5608 - accuracy: 0.1418 - val_loss: 3.0492 - val_accuracy: 0.2471 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.5391 - accuracy: 0.1435\n",
      "Epoch 7: val_accuracy improved from 0.24714 to 0.28314, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 63s 699ms/step - loss: 3.5391 - accuracy: 0.1435 - val_loss: 3.0684 - val_accuracy: 0.2831 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4475 - accuracy: 0.1557\n",
      "Epoch 8: val_accuracy did not improve from 0.28314\n",
      "90/90 [==============================] - 62s 692ms/step - loss: 3.4475 - accuracy: 0.1557 - val_loss: 2.9843 - val_accuracy: 0.2717 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4225 - accuracy: 0.1658\n",
      "Epoch 9: val_accuracy did not improve from 0.28314\n",
      "90/90 [==============================] - 63s 703ms/step - loss: 3.4225 - accuracy: 0.1658 - val_loss: 2.9549 - val_accuracy: 0.2570 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3716 - accuracy: 0.1738\n",
      "Epoch 10: val_accuracy did not improve from 0.28314\n",
      "90/90 [==============================] - 59s 650ms/step - loss: 3.3716 - accuracy: 0.1738 - val_loss: 3.0440 - val_accuracy: 0.2520 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3026 - accuracy: 0.1923\n",
      "Epoch 11: val_accuracy improved from 0.28314 to 0.30769, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 57s 636ms/step - loss: 3.3026 - accuracy: 0.1923 - val_loss: 2.9548 - val_accuracy: 0.3077 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.2953 - accuracy: 0.1909\n",
      "Epoch 12: val_accuracy did not improve from 0.30769\n",
      "90/90 [==============================] - 54s 592ms/step - loss: 3.2953 - accuracy: 0.1909 - val_loss: 3.0771 - val_accuracy: 0.2390 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.2400 - accuracy: 0.2034\n",
      "Epoch 13: val_accuracy did not improve from 0.30769\n",
      "90/90 [==============================] - 50s 558ms/step - loss: 3.2400 - accuracy: 0.2034 - val_loss: 2.9346 - val_accuracy: 0.2946 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.2179 - accuracy: 0.2194\n",
      "Epoch 14: val_accuracy did not improve from 0.30769\n",
      "90/90 [==============================] - 50s 557ms/step - loss: 3.2179 - accuracy: 0.2194 - val_loss: 3.1709 - val_accuracy: 0.2111 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.2063 - accuracy: 0.2069\n",
      "Epoch 15: val_accuracy did not improve from 0.30769\n",
      "90/90 [==============================] - 51s 569ms/step - loss: 3.2063 - accuracy: 0.2069 - val_loss: 2.9683 - val_accuracy: 0.3011 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.1959 - accuracy: 0.2191\n",
      "Epoch 16: val_accuracy did not improve from 0.30769\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "90/90 [==============================] - 50s 554ms/step - loss: 3.1959 - accuracy: 0.2191 - val_loss: 3.0210 - val_accuracy: 0.3077 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.1698 - accuracy: 0.2316\n",
      "Epoch 17: val_accuracy improved from 0.30769 to 0.32897, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 51s 562ms/step - loss: 3.1698 - accuracy: 0.2316 - val_loss: 2.7877 - val_accuracy: 0.3290 - lr: 5.0000e-05\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.1130 - accuracy: 0.2396\n",
      "Epoch 18: val_accuracy improved from 0.32897 to 0.34534, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 56s 621ms/step - loss: 3.1130 - accuracy: 0.2396 - val_loss: 2.7442 - val_accuracy: 0.3453 - lr: 5.0000e-05\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.0646 - accuracy: 0.2490\n",
      "Epoch 19: val_accuracy improved from 0.34534 to 0.41735, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/resnet50_best.h5\n",
      "90/90 [==============================] - 56s 625ms/step - loss: 3.0646 - accuracy: 0.2490 - val_loss: 2.6685 - val_accuracy: 0.4173 - lr: 5.0000e-05\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.0707 - accuracy: 0.2581\n",
      "Epoch 20: val_accuracy did not improve from 0.41735\n",
      "90/90 [==============================] - 58s 644ms/step - loss: 3.0707 - accuracy: 0.2581 - val_loss: 2.8869 - val_accuracy: 0.3110 - lr: 5.0000e-05\n",
      "\n",
      "Best: 0.4173\n"
     ]
    }
   ],
   "source": [
    "# Train ResNet50\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING RESNET50\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "callbacks_resnet = [\n",
    "    ModelCheckpoint(str(MODELS_PATH / 'resnet50_best.h5'), monitor='val_accuracy',\n",
    "                    save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history_resnet = model_resnet.fit(\n",
    "    train_gen, epochs=EPOCHS, validation_data=val_gen,\n",
    "    callbacks=callbacks_resnet, verbose=1\n",
    ")\n",
    "\n",
    "model_resnet.save(MODELS_PATH / 'resnet50_last.h5')\n",
    "print(f\"\\nBest: {max(history_resnet.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: EfficientNet-B0 (Fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building EfficientNet...\n",
      "Trainable params: 2,026,839\n"
     ]
    }
   ],
   "source": [
    "def build_efficientnet():\n",
    "    \"\"\"EfficientNet with top layers unfrozen\"\"\"\n",
    "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Unfreeze top 20 layers\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Building EfficientNet...\")\n",
    "model_eff = build_efficientnet()\n",
    "trainable = sum([tf.size(w).numpy() for w in model_eff.trainable_weights])\n",
    "print(f\"Trainable params: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING EFFICIENTNET-B0\n",
      "================================================================================\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.7240 - accuracy: 0.0310\n",
      "Epoch 1: val_accuracy improved from -inf to 0.03437, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/efficientnet_best.h5\n",
      "90/90 [==============================] - 60s 449ms/step - loss: 3.7240 - accuracy: 0.0310 - val_loss: 3.7356 - val_accuracy: 0.0344 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.7021 - accuracy: 0.0268\n",
      "Epoch 2: val_accuracy did not improve from 0.03437\n",
      "90/90 [==============================] - 37s 413ms/step - loss: 3.7021 - accuracy: 0.0268 - val_loss: 3.7605 - val_accuracy: 0.0245 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.6470 - accuracy: 0.0414\n",
      "Epoch 3: val_accuracy did not improve from 0.03437\n",
      "90/90 [==============================] - 41s 454ms/step - loss: 3.6470 - accuracy: 0.0414 - val_loss: 3.8278 - val_accuracy: 0.0245 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.5638 - accuracy: 0.0540\n",
      "Epoch 4: val_accuracy did not improve from 0.03437\n",
      "\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "90/90 [==============================] - 43s 470ms/step - loss: 3.5638 - accuracy: 0.0540 - val_loss: 4.4429 - val_accuracy: 0.0245 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.5239 - accuracy: 0.0488\n",
      "Epoch 5: val_accuracy did not improve from 0.03437\n",
      "90/90 [==============================] - 42s 466ms/step - loss: 3.5239 - accuracy: 0.0488 - val_loss: 3.9010 - val_accuracy: 0.0245 - lr: 1.5000e-04\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4950 - accuracy: 0.0568\n",
      "Epoch 6: val_accuracy improved from 0.03437 to 0.04092, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/efficientnet_best.h5\n",
      "90/90 [==============================] - 41s 451ms/step - loss: 3.4950 - accuracy: 0.0568 - val_loss: 4.3041 - val_accuracy: 0.0409 - lr: 1.5000e-04\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4980 - accuracy: 0.0585\n",
      "Epoch 7: val_accuracy did not improve from 0.04092\n",
      "\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "90/90 [==============================] - 42s 460ms/step - loss: 3.4980 - accuracy: 0.0585 - val_loss: 6.4581 - val_accuracy: 0.0278 - lr: 1.5000e-04\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4678 - accuracy: 0.0617\n",
      "Epoch 8: val_accuracy improved from 0.04092 to 0.05728, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/efficientnet_best.h5\n",
      "90/90 [==============================] - 53s 586ms/step - loss: 3.4678 - accuracy: 0.0617 - val_loss: 3.4575 - val_accuracy: 0.0573 - lr: 7.5000e-05\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4516 - accuracy: 0.0676\n",
      "Epoch 9: val_accuracy improved from 0.05728 to 0.06874, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/efficientnet_best.h5\n",
      "90/90 [==============================] - 63s 699ms/step - loss: 3.4516 - accuracy: 0.0676 - val_loss: 3.4594 - val_accuracy: 0.0687 - lr: 7.5000e-05\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4746 - accuracy: 0.0630\n",
      "Epoch 10: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 53s 592ms/step - loss: 3.4746 - accuracy: 0.0630 - val_loss: 3.7727 - val_accuracy: 0.0458 - lr: 7.5000e-05\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4471 - accuracy: 0.0752\n",
      "Epoch 11: val_accuracy did not improve from 0.06874\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "90/90 [==============================] - 45s 494ms/step - loss: 3.4471 - accuracy: 0.0752 - val_loss: 3.7330 - val_accuracy: 0.0475 - lr: 7.5000e-05\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4324 - accuracy: 0.0714\n",
      "Epoch 12: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 45s 497ms/step - loss: 3.4324 - accuracy: 0.0714 - val_loss: 4.2853 - val_accuracy: 0.0245 - lr: 3.7500e-05\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4124 - accuracy: 0.0711\n",
      "Epoch 13: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 42s 461ms/step - loss: 3.4124 - accuracy: 0.0711 - val_loss: 4.4349 - val_accuracy: 0.0245 - lr: 3.7500e-05\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4176 - accuracy: 0.0700\n",
      "Epoch 14: val_accuracy did not improve from 0.06874\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "90/90 [==============================] - 43s 475ms/step - loss: 3.4176 - accuracy: 0.0700 - val_loss: 4.3685 - val_accuracy: 0.0245 - lr: 3.7500e-05\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.4065 - accuracy: 0.0850\n",
      "Epoch 15: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 46s 504ms/step - loss: 3.4065 - accuracy: 0.0850 - val_loss: 3.8478 - val_accuracy: 0.0475 - lr: 1.8750e-05\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3834 - accuracy: 0.0867\n",
      "Epoch 16: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 60s 665ms/step - loss: 3.3834 - accuracy: 0.0867 - val_loss: 3.7586 - val_accuracy: 0.0491 - lr: 1.8750e-05\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3859 - accuracy: 0.0794\n",
      "Epoch 17: val_accuracy did not improve from 0.06874\n",
      "\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 9.375000445288606e-06.\n",
      "90/90 [==============================] - 42s 461ms/step - loss: 3.3859 - accuracy: 0.0794 - val_loss: 3.6914 - val_accuracy: 0.0458 - lr: 1.8750e-05\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3534 - accuracy: 0.0822\n",
      "Epoch 18: val_accuracy did not improve from 0.06874\n",
      "90/90 [==============================] - 46s 506ms/step - loss: 3.3534 - accuracy: 0.0822 - val_loss: 4.1802 - val_accuracy: 0.0376 - lr: 9.3750e-06\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 3.3565 - accuracy: 0.0895\n",
      "Epoch 19: val_accuracy did not improve from 0.06874\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "90/90 [==============================] - 44s 489ms/step - loss: 3.3565 - accuracy: 0.0895 - val_loss: 4.2093 - val_accuracy: 0.0426 - lr: 9.3750e-06\n",
      "Epoch 19: early stopping\n",
      "\n",
      "Best: 0.0687\n"
     ]
    }
   ],
   "source": [
    "# Train EfficientNet\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING EFFICIENTNET-B0\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "callbacks_eff = [\n",
    "    ModelCheckpoint(str(MODELS_PATH / 'efficientnet_best.h5'), monitor='val_accuracy',\n",
    "                    save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history_eff = model_eff.fit(\n",
    "    train_gen, epochs=EPOCHS, validation_data=val_gen,\n",
    "    callbacks=callbacks_eff, verbose=1\n",
    ")\n",
    "\n",
    "model_eff.save(MODELS_PATH / 'efficientnet_last.h5')\n",
    "print(f\"\\nBest: {max(history_eff.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: MobileNetV2 (Fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building MobileNetV2...\n",
      "Trainable params: 1,881,959\n"
     ]
    }
   ],
   "source": [
    "def build_mobilenet():\n",
    "    \"\"\"MobileNetV2 with top layers unfrozen\"\"\"\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Unfreeze top 20 layers\n",
    "    base.trainable = True\n",
    "    for layer in base.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0003),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "print(\"Building MobileNetV2...\")\n",
    "model_mobile = build_mobilenet()\n",
    "trainable = sum([tf.size(w).numpy() for w in model_mobile.trainable_weights])\n",
    "print(f\"Trainable params: {trainable:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING MOBILENETV2\n",
      "================================================================================\n",
      "Epoch 1/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 1.2771 - accuracy: 0.6897\n",
      "Epoch 1: val_accuracy improved from -inf to 0.89198, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 26s 269ms/step - loss: 1.2771 - accuracy: 0.6897 - val_loss: 0.3668 - val_accuracy: 0.8920 - lr: 3.0000e-04\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9537\n",
      "Epoch 2: val_accuracy improved from 0.89198 to 0.94108, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 25s 280ms/step - loss: 0.1678 - accuracy: 0.9537 - val_loss: 0.2141 - val_accuracy: 0.9411 - lr: 3.0000e-04\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0881 - accuracy: 0.9749\n",
      "Epoch 3: val_accuracy did not improve from 0.94108\n",
      "90/90 [==============================] - 27s 300ms/step - loss: 0.0881 - accuracy: 0.9749 - val_loss: 0.2202 - val_accuracy: 0.9313 - lr: 3.0000e-04\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9833\n",
      "Epoch 4: val_accuracy improved from 0.94108 to 0.96072, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 29s 314ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.1442 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0508 - accuracy: 0.9843\n",
      "Epoch 5: val_accuracy improved from 0.96072 to 0.97381, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 28s 314ms/step - loss: 0.0508 - accuracy: 0.9843 - val_loss: 0.1103 - val_accuracy: 0.9738 - lr: 3.0000e-04\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9868\n",
      "Epoch 6: val_accuracy did not improve from 0.97381\n",
      "90/90 [==============================] - 31s 341ms/step - loss: 0.0440 - accuracy: 0.9868 - val_loss: 0.1954 - val_accuracy: 0.9525 - lr: 3.0000e-04\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9906\n",
      "Epoch 7: val_accuracy did not improve from 0.97381\n",
      "90/90 [==============================] - 37s 408ms/step - loss: 0.0265 - accuracy: 0.9906 - val_loss: 0.1747 - val_accuracy: 0.9591 - lr: 3.0000e-04\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9868\n",
      "Epoch 8: val_accuracy improved from 0.97381 to 0.97545, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 39s 428ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0921 - val_accuracy: 0.9755 - lr: 3.0000e-04\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9909\n",
      "Epoch 9: val_accuracy did not improve from 0.97545\n",
      "90/90 [==============================] - 35s 385ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.1345 - val_accuracy: 0.9656 - lr: 3.0000e-04\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9937\n",
      "Epoch 10: val_accuracy improved from 0.97545 to 0.98036, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 37s 401ms/step - loss: 0.0290 - accuracy: 0.9937 - val_loss: 0.1141 - val_accuracy: 0.9804 - lr: 3.0000e-04\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9937\n",
      "Epoch 11: val_accuracy improved from 0.98036 to 0.98363, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 34s 375ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.0822 - val_accuracy: 0.9836 - lr: 3.0000e-04\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9944\n",
      "Epoch 12: val_accuracy did not improve from 0.98363\n",
      "90/90 [==============================] - 34s 375ms/step - loss: 0.0231 - accuracy: 0.9944 - val_loss: 0.0726 - val_accuracy: 0.9820 - lr: 3.0000e-04\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0290 - accuracy: 0.9906\n",
      "Epoch 13: val_accuracy did not improve from 0.98363\n",
      "90/90 [==============================] - 34s 370ms/step - loss: 0.0290 - accuracy: 0.9906 - val_loss: 0.1238 - val_accuracy: 0.9738 - lr: 3.0000e-04\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9864\n",
      "Epoch 14: val_accuracy did not improve from 0.98363\n",
      "90/90 [==============================] - 35s 383ms/step - loss: 0.0469 - accuracy: 0.9864 - val_loss: 0.3187 - val_accuracy: 0.9427 - lr: 3.0000e-04\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0358 - accuracy: 0.9892\n",
      "Epoch 15: val_accuracy did not improve from 0.98363\n",
      "\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "90/90 [==============================] - 38s 414ms/step - loss: 0.0358 - accuracy: 0.9892 - val_loss: 0.2057 - val_accuracy: 0.9607 - lr: 3.0000e-04\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0129 - accuracy: 0.9958\n",
      "Epoch 16: val_accuracy did not improve from 0.98363\n",
      "90/90 [==============================] - 37s 405ms/step - loss: 0.0129 - accuracy: 0.9958 - val_loss: 0.0961 - val_accuracy: 0.9820 - lr: 1.5000e-04\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9976\n",
      "Epoch 17: val_accuracy improved from 0.98363 to 0.98691, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 43s 472ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0596 - val_accuracy: 0.9869 - lr: 1.5000e-04\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9972\n",
      "Epoch 18: val_accuracy improved from 0.98691 to 0.99018, saving model to /Users/kevin/Documents/GitHub/Python/VESKL/11.DAE/NEU/NEU_IE7615/Prj/Discriminative/G8/CNN_Attendance_System/models/classification/mobilenet_best.h5\n",
      "90/90 [==============================] - 44s 485ms/step - loss: 0.0105 - accuracy: 0.9972 - val_loss: 0.0353 - val_accuracy: 0.9902 - lr: 1.5000e-04\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0078 - accuracy: 0.9979\n",
      "Epoch 19: val_accuracy did not improve from 0.99018\n",
      "90/90 [==============================] - 43s 476ms/step - loss: 0.0078 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9885 - lr: 1.5000e-04\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 20: val_accuracy did not improve from 0.99018\n",
      "90/90 [==============================] - 36s 392ms/step - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0195 - val_accuracy: 0.9902 - lr: 1.5000e-04\n",
      "\n",
      "Best: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# Train MobileNetV2\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING MOBILENETV2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "callbacks_mobile = [\n",
    "    ModelCheckpoint(str(MODELS_PATH / 'mobilenet_best.h5'), monitor='val_accuracy',\n",
    "                    save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history_mobile = model_mobile.fit(\n",
    "    train_gen, epochs=EPOCHS, validation_data=val_gen,\n",
    "    callbacks=callbacks_mobile, verbose=1\n",
    ")\n",
    "\n",
    "model_mobile.save(MODELS_PATH / 'mobilenet_last.h5')\n",
    "print(f\"\\nBest: {max(history_mobile.history['val_accuracy']):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary After small Epochs Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "5-EPOCH TEST RESULTS\n",
      "================================================================================\n",
      "       model  best_val_acc\n",
      " MobileNetV2      0.990180\n",
      "  Custom CNN      0.864157\n",
      "    ResNet50      0.417349\n",
      "EfficientNet      0.068740\n",
      "\n",
      "================================================================================\n",
      "DECISION\n",
      "================================================================================\n",
      "\n",
      "If all models >70% after 5 epochs:\n",
      "  -> Increase EPOCHS to 50 and retrain all\n",
      "\n",
      "If some models <50% after 5 epochs:\n",
      "  -> Focus only on models with >70%\n",
      "  -> Adjust LR for struggling models\n",
      "\n",
      "Current best: MobileNetV2 at 99.0%\n"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    {'model': 'Custom CNN', 'best_val_acc': max(history_cnn.history['val_accuracy'])},\n",
    "    {'model': 'ResNet50', 'best_val_acc': max(history_resnet.history['val_accuracy'])},\n",
    "    {'model': 'EfficientNet', 'best_val_acc': max(history_eff.history['val_accuracy'])},\n",
    "    {'model': 'MobileNetV2', 'best_val_acc': max(history_mobile.history['val_accuracy'])},\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(results).sort_values('best_val_acc', ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5-EPOCH TEST RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DECISION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nIf all models >70% after 5 epochs:\")\n",
    "print(\"  -> Increase EPOCHS to 50 and retrain all\")\n",
    "print(\"\\nIf some models <50% after 5 epochs:\")\n",
    "print(\"  -> Focus only on models with >70%\")\n",
    "print(\"  -> Adjust LR for struggling models\")\n",
    "\n",
    "best = df.iloc[0]\n",
    "print(f\"\\nCurrent best: {best['model']} at {best['best_val_acc']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After verifying small epochs work, change EPOCHS=50 and rerun"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
